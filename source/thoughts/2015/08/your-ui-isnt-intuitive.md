---
title: Your UI Isn't Intuitive
description: Getting a handle on stratification and user interfaces.
date: 2015-08-10
tags:
---

Designing intuitive interfaces shouldn't be about appealing to patronizing
ideas of the "lowest common denominator", instead we should be focusing on
adaptable design for whatever level of fluency a user has, but what's holding
us back?  For one, the terms "digital native" and "digital immigrant" still
inform a lot of how we design, and that's probably for the worse.

What are we talking about when we use the terms "digital native" and, its
inverse, "digital immigrant"?  Well, if we go by the authors of "Born Digital:
Understanding The First Generation of Digital Natives", we get this definition
of digital natives:

> They were all born after 1980, when social digital technologies, such as
Usenet and bulletin board systems, came online. They all have access to
networked digital technologies. And they all have the skills to use those
technologies.  (Except for the babyâ€”but she'll learn soon enough.)

Not only is that casting a wide net over generations of people, I'm certain
that in the 1980's the sentence "they **all** have access to networked digital
technologies" wasn't a true statement. And, yet, three decades into the lives
of supposed digital natives, and we're designing as if that sentence suddenly
rings true. We still use the of rhetoric of digital natives, in part, because
we find it convenient to understand anyone born after the 1980's as a group,
particularly a group we can target. Anyone born after 1980 is apparently a part
of a consumer group with a shared set of knowledge and habits that constitute a
"natural" digital ease. Unfortunately, the digital revolution was never equal,
and in the last 35 years that hasn't changed. Our designs should take that
to heart.

For the flip side, what does "digital immigrant" mean? Beyond the obvious
inverse of the digital native definition (i.e. anyone born before the 1980's),
being a digital immigrant carries with it a way of understanding how one
relates to technology. Because a digital immigrant apparently lacks a life
long, deep seated exposure to technology, there's the sense that being digital
immigrant is a hardship: it's about learning and keeping up with kids whose
technology is increasingly affecting everyone's lives.

---

## A Note On Vocabulary

Let's also take a moment to recognize that this terminology on the whole marks
immigration as an inherently other-ing experience. It's a label for a group
defined by their struggle to assimilate with supposed digital natives. This is
not only ignorant of the experiences of immigrants and their ability to
contribute and thrive in the nations they immigrate to, it's also incredibly
appropriative of an experience that has produced trauma for billions of people.
I'm using the phrase here because it's a vocabulary I am critiquing, but it
should be noted that not only is the design that comes out of the "digital
native/immigrant" mindset sub-par, the terms themselves are disrespectful at
best, ignorant at worst. Even when the man who coined these terms now
[disagrees with the
terms](http://marcprensky.com/writing/Prensky-Intro_to_From_DN_to_DW.pdf).

---

The continued use of these terms seems to me like the idea of meritocracy in
the tech world. In a meritocracy, the assumption goes, if you're just "smart
enough" or work "hard enough" you can be successful in tech. This is a myth
that ignores reality: many people don't have the access, education, or
mentorship necessary to make it in tech by themselves. Really, it's nothing
more than the old ["bootstraps"
narrative](http://ideas.time.com/2012/09/07/the-myth-of-bootstrapping/) applied
to digital workers.

There has been push back against this meritocracy though. With the recent surge
in diversity efforts, VC's and tech companies are now starting to recognize the
error of a false meritocracy, that women and minorities don't have the same
access or the same cultural disposition to just "make it." You can't have a
meritocracy when people don't have the same ability to gain those merits. We
need to step back and make this same realization about users.

Just as we recognize that future programmers, designers, and executives don't
always have the means to get into the tech world, not all users have the
background or the relationship with technology to find supposedly intuitive
interfaces easy to navigate. If you're making something you want anyone to be
able to use, then you have to design with as few assumptions as possible, and
recognize the details that you _assume_ people are familiar with.

## Examining Our Assumptions

So what are some things we assume about users when we understand them as
digital natives or well-adjusted digital immigrants? Well, a couple
examples might be helpful:

### Icons

 [Icons are inherently
 inaccessible](http://www.nngroup.com/articles/icon-usability/), as they are
 based on user's standing familiarity with icon's and their attached meaning.
 Today,  icons draw from two different previous experiences: the mobile space
 and 'traditional', technologically ubiquitous icons. In the first category I'm
 talking about icons like the o-so-popular hamburger menu (â˜°).   While you can
 assume that [2/3rds of your American adult users have a
 smartphone](http://www.pewinternet.org/2015/04/01/us-smartphone-use-in-2015/)
 what about that last 1/3rd? What about the users who are getting, and those
 who will have to get, used to mobile interfaces as smartphone market
 penetration rises - who don't have familiarity with these icons? And what
 about the world over, the billions of people who will, young and old, be
 introduced to smart phones and computers (probably in that order) in
 generations to come? You can't assume someone will be there to show the next
 person what an icon means when entire communities will be learning, for the
 first time, how to interact with digital interfaces on a daily basis.

In the latter group we have icons like the traditional save icon (ðŸ’¾). While a
lot of users who have had to get used to computer interfaces will be familiar
with it, question your design decisions with familiar icons as they relate to
users who might not recognize them: when you put it in the corner and make it
smaller, to get it "out of the way", are you really just obscuring a critical
part of your interface for users who might not be used to your
color scheme/shading/placement of the icon? And beyond first time computer
users, think about users who have irregular access to their means of
technology, those who may not consistently remember that this (ðŸ’¾) means 'save'.

If you really want to make sure everyone knows what every piece of your product
does, don't assume anything about users' iconographic fluency, and just write
it out. You could at least make it an option to label every icon for users who
have trouble recognizing your icons for any of the reasons mentioned above.

## Keyboard Accessibility (A Double Edged Sword).

On one hand, if someone can't navigate something without the use of a keyboard,
it can be [a complete disaster](http://www.webaxe.org/apples-inaccessibility/).
On the other hand, if you make something _only_ keyboard accessible, you shut
out users who prefer the more intuitive mouse or touch screen interfaces. As
people who work with computers day-in and day-out, I think there's a tendency
to forget about the possibilities of keyboard-less interaction space. We should
be designing for both, to best accommodate the full range of user experiences
whether that means comfortability with lighting quick keyboard shortcuts, or
anymore intuitive  and fluid touch/pointer interface.  This shouldn't be a pain
point for your design process, it's an opportunity for you to bring your
product to as many people as possible, and, excitingly, a way to test your
abilities as a designer, of interfaces, of experiences, or anything else.

Many people take these things for granted (I know I do, every day), because
these elements are ubiquitous in our own lives. But, there are still people who
don't have regular, intimate access to computers or the latest mobile
technology. When someone is looking for healthcare information on a public
computer with a browser  When a kid comes into a classroom and has to deal with
an interface that has symbols they don't inherently ("natively") recognize,
you're going to have a much tougher time getting that kid to use that interface
for learning, a process that's already hard enough.

People resembling digital natives exist, but just like we're learning to reject
the idea that tech is a meritocracy, that everyone can make it if they just
"work hard enough", we need to unlearn the idea that every child is a digital
native, and that every adult has a smartphone, or for even those who do have
access to these technologies, that they use their technology as intimately and
consistently as tech advertisements would have you believe. Software is eating
the world, sure, but the keyword in that phrase is "**is**", meaning present
tense. Software hasn't eaten the world completely, and it definitely hasn't
done so evenly across populations. We have to remember that accessibility in
our interfaces isn't just a feature or a goal - if you want to be able to
impact anyone with your design, you should be designing, building, and testing
around every use case, designing interfaces that adapt to levels of
comfortability and experience with technologies.

<!-- <style> -->
<!-- li[id^="fn:"]:focus { -->
<!--     padding&#45;top: 12%; -->
<!-- } -->
<!-- </style> -->
<!--  -->
<!-- This is some text[^1]. Other text[^footnote]. -->
<!--  -->
<!-- This is some text not written in HTML but in another language! -->
<!--  -->
<!-- *[another language]: It's called Markdown -->
<!--  -->
<!-- *[HTML]: HyperTextMarkupLanguage -->
<!-- {:.mega&#45;big} -->
<!--  -->
<!-- [^1]: Some *crazy* footnote definition. -->
<!--  -->
<!-- [^footnote]: -->
<!--     > Blockquotes can be in a footnote. -->
<!--  -->
<!--         as well as code blocks -->
<!--  -->
<!--     or, naturally, simple paragraphs. -->
<!--  -->
